 # TỔNG QUAN #

$${\color{green}Tổng \space quan}$$

Kiểm tra các file trên máy chủ nếu chúng có tiết lộ các thông tin nhạt cảm. Các file này có thể có thông tin về cấu trúc web và cách chúng hoạt động

$${\color{green}Vấn \space đề}$$

- Rủi ro bảo mật: kẻ xấu có thể lợi dụng để khai thác các thông tin mật
- Đường dẫn ẩn: Chúng có thể tiết lộ những đường dẫn ẩn của trang web

 # ROBOTS #

$${\color{green}Định \space nghĩa}$$

Web Spiders, Robots, hoặc trình thu thập là các chương trình tự động sẽ đi đến các trang web và đường link để lấy dữ liệu. Chúng thường được các công cụ tìm kiếm sử dụng để lập các chỉ mục web hoặc bởi các công cụ bảo mật để phân tích ứng dụng web 

$${\color{green}Cách \space hoạt \space động}$$

1.Robots sẽ bắt đầu từ việc truy cập vào trang web
2. Tiếp đến chúng sẽ tự động đi thưo các hyperlinks từ trang này sang trang khác trong cùng 1 website
3. Chúng thu thập thông tin qua các trang này

$${\color{green}Ví \space dụ}$$

`robots.txt` file từ [Facebook](https://facebook.com/robots.txt)

>User-agent: Amazonbot
>Disallow: /
>
>User-agent: Applebot-Extended
>Disallow: /

Phần này của file `robots.txt` cung cấp các chỉ thị cho các bot hoặc trình thu thập dữ liệu, yêu cầu chúng không được truy cập bất kỳ phần nào trong website

Ví dụ, `User-Agent: Amazonbot` là con bot của Google trong khi `User-Agent: Applebot-Extended` là trình thu thập dữ liệu của Microsoft. User-Agent: * trong ví dụ trên không được phép truy cập vào bất kì phần nào trong trang

>Disallow: /*/plugins/*
>Disallow: /?*next=
>Disallow: /a/bz?
>Disallow: /ajax/
>Disallow: /album.php

`/*/plugins/*` ( chặn truy cập vào bất kỳ URL nào có chứa /plugins/ trong bất kỳ đoạn nào )

`/?*next=` ( chặn các URL có tham số truy vấn  `next=`)

`/a/bz?` ( chặn các URL trùng khớp chính xác với đường dẫn này)

`/ajax/` ( chặn truy cập các URL bắt đầu bằng `/ajax/`)

`/album.php` ( chặn tệp tin )

- File `robots.txt` được lấy từ thư mục gốc của máy chủ web . Ví dụ, để lấy tệp `robots.txt` từ www.google.com bằng cách sử dụng `wget` hoặc `curl`:

- Đầu tiên, tải xuống tệp bằng lệnh 'curl'
>curl -O -Ss http://www.google.com/robots.txt

- Sử dụng `cat` để xem nội dung file:
>cat robots.txt

![image](https://github.com/user-attachments/assets/413c08fa-14bf-42ae-8971-bcfda320beb6)

# PHÂN TÍCH FILE ROBOTS.TXT BẰNG GOOGLE WEBMASTER TOOLS #
 
Ta có thể sử dụng chức năng “Analyze robots.txt” của Google để phân tích trang web [Google Webmaster Tools](https://search.google.com/search-console/welcome?hl=en&utm_source=wmx&utm_medium=deprecation-pane&utm_content=home). 

1.Đăng nhập vào Google Webmaster Tools bằng tài khoản Google của bạn.

2.Nhập URL bạn muốn phân tích.

3.Chọn phương pháp phân tích và làm theo hướng dẫndẫn.

# THẺ META #

$${\color{green}Định \space nghĩa}$$

Thẻ META thường được đặt trong phần `<head>` của HTML. Chúng cung cấp thông tin quan trọng về trang web cho các trình duyệt, công cụ tìm kiếm và các trình thu thập dữ liệu khác. Việc thẻ META được sử dụng nhất quán trên toàn bộ trang web giúp đảm bảo các công cụ tìm kiếm, trình thu thập dữ liệu có thể hiểu  và lập chỉ mục chính xác, bất kể chúng truy cập trang web từ đâu.

$${\color{green}Ý \space chính}$$

**1. Tính nhất quán trên trang web :**

- Cần đảm bảo rằng các thẻ META như `description`, `keyword`, `robots` có sự đồng nhất trên toàn bộ trang web để tránh sự khác biệt trong cách các trang được lập chỉ mục và hiển thị

**2. Thẻ META robots:**

- Thẻ META `robots` cung cấp các chỉ thị cho trình thu thập dữ liệu web về cách lập chỉ mục và theo dõi các liên kết trên trang

![image](https://github.com/user-attachments/assets/a3f5f747-c435-4359-8609-6e752ce02685)

- Một vài mục phổ biến trong thẻ `robots`:
  - `index`, `follow`: Cho phép lập chỉ mục và theo dõi các liên kết
  - `noindex`, `follow`: Không lập chỉ mục các trang nhưng vẫn theo dõi các liên kết
  - `index`, `nofollow`: Lập chỉ mục trang nhưng không theo dõi các liên kết.
  - `noindex`, `nofollow`: Không lập chỉ mục trang và không theo dõi các liên kết.
    
**3. Robots.txt và thẻ META :**

- Cả `robots.txt` và thẻ META đều kiểm soát việc thu thập thông tin và lập chỉ mục nhưng chúng có mục đích khác nhau
  - robots.txt: Dùng để kiểm soát quyền truy cập vào các phần của trang web đối với tất cả trình thu thập dữ liệu, thường áp dụng đối với toàn trang web. Ví dụ: sử dụng `robots.txt` để ngăn các bot truy cập vào thư mục nào đó trên trang web
  - META Tags: Cung cấp chỉ thị cụ thể cho từng trang,chặn một trang cụ thể không được lập chỉ mục dù vẫn có thể truy cập được vào toàn bộ trang web đó. Ví dụ bạn không muốn trang `/acount.html` của bạn không được lập chỉ mục, bạn có thể thêm thẻ META này vào file HTML của `/acount.html`
 
> `<meta name="robots" content="noindex, nofollow">`  
    
**4.Thẻ META chứa nhiều thông tin:**

-  Các tổ chức thường thêm các thẻ META vào nội dung web để hỗ trợ công nghệ, ví dụ như trình đọc màn hình, công cụ tìm kiếm,... Những thẻ META này rất hữu ích cho các kiểm thử viên trong việc xác định loại công nghệ được sử dụng, các đường dẫn, chức năng để kiểm tra

Thông tin dưới đây được lấy từ [The New York Times](https://www.nytimes.com/2024/08/27/books/review/at-war-with-ourselves-hr-mcmaster.html) 

Thông qua nguồn

![image](https://github.com/user-attachments/assets/31125690-d782-4d8c-9a27-c40a04a593d1)


# Sơ đồ trang web #

A sitemap is a file where a developer or organization can provide information about the pages, videos, and other files offered by the site or application, and the relationship between them. Search engines can use this file to more intelligently explore your site. Testers can use `sitemap.xml` files to learn more about the site or application to explore it more completely.

Sơ đồ trang web là tệp tin mà nhà phát triển sử dụng để cung cấp thông tin về trang, video và các tệp tin khác của trang web hoặc ứng dụng, cùng mỗi liên kết giữu chung. Các công cụ tìm kiếm sử dụng file này để có thể dễ dàng đào sâu vào trang web hơn. Các kiểm thử viên cũng sử dụng `sitemap.xml` để hiểu hơn về trang web/ứng dụng 

ví dụ, đây là file `sitemap.xml` củacủa Google

![image](https://github.com/user-attachments/assets/e1a14c09-1285-455b-a1d3-b2fc120496f0)

# SECURITY.TXT #

- File `security.txt` là tiêu chuẩn cho thông tin bảo mật của web, cho phép các nhà nghiên cứu bảo mật báo cáo các lỗ hổng một cách dễ dàng

Tệp này có thể xuất hiện trong thư mục gốc của web hoặc trong  mục `.well-known/` . Ví dụ

- `https://example.com/security.txt`
- `https://example.com/.well-known/security.txt`

Ví dụ từ trang [Facebook](https://www.facebook.com/security.txt)

![image](https://github.com/user-attachments/assets/5a5217ea-3d95-4576-b15f-d3f450e9778b)

# HUMANS.TXT #

- Đây là file cung cấp thông tin về những người đã thanh lập nên trang web

Ví dụ từ trang [Google](https://www.google.com/humans.txt)

![image](https://github.com/user-attachments/assets/4da4c3bb-87c5-494a-8ca8-58bb4d57d4ec)


